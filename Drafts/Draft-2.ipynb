{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:39:33.532680Z",
     "start_time": "2025-01-11T23:39:30.709676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#=============================\n",
    "# 1. MÔ HÌNH VAE\n",
    "#=============================\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, latent_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        mean = self.fc2_mean(h)\n",
    "        logvar = self.fc2_logvar(h)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc3(z))\n",
    "        x_recon = self.fc4(h)\n",
    "        return x_recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mean, logvar\n",
    "\n",
    "def vae_loss_fn(x, x_recon, mean, logvar):\n",
    "    \"\"\"\n",
    "    Reconstruction loss + KL-divergence\n",
    "    \"\"\"\n",
    "    recon_loss = F.mse_loss(x_recon, x, reduction='sum')\n",
    "    # KL divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_loss\n",
    "\n",
    "\n",
    "#=============================\n",
    "# 2. MODULE POS ENCODING & TRANSFORMER (GIỮ NGUYÊN)\n",
    "#=============================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        L = x.size(1)\n",
    "        return x + self.pe[:, :L, :].to(x.device)\n",
    "\n",
    "class TransformerDetector(nn.Module):\n",
    "    def __init__(self, input_size, d_model=128, nhead=8, num_layers=2, dim_feedforward=256, dropout=0.1):\n",
    "        super(TransformerDetector, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward, \n",
    "                                                   dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:  \n",
    "            x = x.unsqueeze(1)\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.fc(x)"
   ],
   "id": "e5408f029679b042",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:39:34.280513Z",
     "start_time": "2025-01-11T23:39:34.272812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#=============================\n",
    "# 3. HÀM TIỆN ÍCH\n",
    "#=============================\n",
    "def load_adbench_data(dataset_path):\n",
    "    data = np.load(dataset_path)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "def evaluate_with_classification_report_and_auc(model, test_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            all_preds.append(y_pred.cpu())\n",
    "            all_labels.append(y_batch.cpu())\n",
    "\n",
    "    preds = torch.cat(all_preds).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    binary_preds = (preds > threshold).astype(int)\n",
    "\n",
    "    report = classification_report(labels, binary_preds, target_names=['Class 0', 'Class 1'])\n",
    "    print(report)\n",
    "\n",
    "    if len(set(labels)) > 1:\n",
    "        aucroc = roc_auc_score(labels, preds)\n",
    "        print(f\"AUC-ROC: {aucroc:.4f}\")\n",
    "    else:\n",
    "        aucroc = None\n",
    "        print(\"AUC-ROC: Undefined (only one class present in labels)\")\n",
    "\n",
    "    return report, aucroc\n",
    "\n",
    "def train_detector(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(X_batch).squeeze()\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)"
   ],
   "id": "fad48c0747ed517a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:41:20.454483Z",
     "start_time": "2025-01-11T23:41:18.590718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#=============================\n",
    "# 4. MAIN: THAY THẾ SMOTE BẰNG VAE\n",
    "#=============================\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"Classical/20_letter.npz\"  # Thay bằng đường dẫn dataset của bạn\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Tải dữ liệu\n",
    "    X, y = load_adbench_data(dataset_path)\n",
    "\n",
    "    # Chia train/test\n",
    "    X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(\n",
    "        X.numpy(), y.numpy(), test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Đổi lại thành tensor\n",
    "    X_train_all = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "    y_train_all = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "    #-------------\n",
    "    # Bước A: TÁCH DỮ LIỆU LỚP THIỂU SỐ\n",
    "    #-------------\n",
    "    # Giả sử bạn xác định lớp 1 là lớp thiểu số. Nếu ngược lại thì tuỳ tình huống.\n",
    "    minority_mask = (y_train_all == 1)\n",
    "    X_minority = X_train_all[minority_mask]\n",
    "    y_minority = y_train_all[minority_mask]\n",
    "\n",
    "    majority_mask = (y_train_all == 0)\n",
    "    X_majority = X_train_all[majority_mask]\n",
    "    y_majority = y_train_all[majority_mask]\n",
    "\n",
    "    print(\"Trước khi oversampling bằng VAE:\")\n",
    "    print(\"Số lượng majority:\", len(X_majority))\n",
    "    print(\"Số lượng minority:\", len(X_minority))\n",
    "\n",
    "    #-------------\n",
    "    # Bước B: ĐỊNH NGHĨA & TRAIN VAE TRÊN DỮ LIỆU THIỂU SỐ\n",
    "    #-------------\n",
    "    input_dim = X_train_all.shape[1]\n",
    "    vae = VAE(input_dim=input_dim, hidden_dim=128, latent_dim=32).to(device)\n",
    "\n",
    "    optimizer_vae = Adam(vae.parameters(), lr=1e-3)\n",
    "    vae_epochs = 200\n",
    "\n",
    "    # DataLoader cho lớp thiểu số\n",
    "    minority_dataset = TensorDataset(X_minority)\n",
    "    minority_loader = DataLoader(minority_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    vae.train()\n",
    "    for epoch in range(vae_epochs):\n",
    "        total_vae_loss = 0\n",
    "        for (x_batch,) in minority_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            x_recon, mean, logvar = vae(x_batch)\n",
    "            loss_vae = vae_loss_fn(x_batch, x_recon, mean, logvar)\n",
    "            optimizer_vae.zero_grad()\n",
    "            loss_vae.backward()\n",
    "            optimizer_vae.step()\n",
    "            total_vae_loss += loss_vae.item()\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{vae_epochs}, VAE Loss = {total_vae_loss/len(minority_loader):.2f}\")\n",
    "\n",
    "    #-------------\n",
    "    # Bước C: SINH THÊM DỮ LIỆU TỪ VAE\n",
    "    #-------------\n",
    "    vae.eval()\n",
    "    # Chọn số lượng mẫu muốn sinh thêm (ví dụ: bằng với số majority để cân bằng)\n",
    "    num_generate = len(X_majority) - len(X_minority)  # Hoặc tuỳ ý\n",
    "    if num_generate <= 0:\n",
    "        num_generate = len(X_minority)  # nếu đã balance rồi thì sinh ít hơn\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Sampling latent vector z ~ N(0, I)\n",
    "        z = torch.randn(num_generate, 32).to(device)\n",
    "        X_synthetic = vae.decode(z)\n",
    "    \n",
    "    # Gán label = 1 cho dữ liệu synthetic\n",
    "    y_synthetic = torch.ones(num_generate, dtype=torch.float32)\n",
    "\n",
    "    # Chuyển về CPU nếu cần\n",
    "    X_synthetic = X_synthetic.cpu()\n",
    "    y_synthetic = y_synthetic.cpu()\n",
    "\n",
    "    print(\"Đã sinh thêm:\", len(X_synthetic), \"mẫu minority bằng VAE\")\n",
    "\n",
    "    #-------------\n",
    "    # Bước D: GHÉP DỮ LIỆU THIỂU SỐ MỚI SINH + DỮ LIỆU GỐC\n",
    "    #-------------\n",
    "    X_train_final = torch.cat([X_majority, X_minority, X_synthetic], dim=0)\n",
    "    y_train_final = torch.cat([y_majority, y_minority, y_synthetic], dim=0)\n",
    "\n",
    "    print(\"Sau khi oversampling bằng VAE:\")\n",
    "    unique, counts = np.unique(y_train_final.numpy(), return_counts=True)\n",
    "    print(\"Phân phối lớp trong tập train:\", dict(zip(unique, counts)))\n",
    "\n",
    "    # Tạo DataLoader cho train & test\n",
    "    train_dataset = TensorDataset(X_train_final, y_train_final)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "    "
   ],
   "id": "8db581353e48550d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước khi oversampling bằng VAE:\n",
      "Số lượng majority: 1200\n",
      "Số lượng minority: 80\n",
      "Epoch 10/200, VAE Loss = 27306.62\n",
      "Epoch 20/200, VAE Loss = 11886.79\n",
      "Epoch 30/200, VAE Loss = 9161.32\n",
      "Epoch 40/200, VAE Loss = 8260.95\n",
      "Epoch 50/200, VAE Loss = 7684.43\n",
      "Epoch 60/200, VAE Loss = 7215.01\n",
      "Epoch 70/200, VAE Loss = 6611.28\n",
      "Epoch 80/200, VAE Loss = 6188.85\n",
      "Epoch 90/200, VAE Loss = 5602.25\n",
      "Epoch 100/200, VAE Loss = 5209.08\n",
      "Epoch 110/200, VAE Loss = 4778.91\n",
      "Epoch 120/200, VAE Loss = 4531.77\n",
      "Epoch 130/200, VAE Loss = 4506.56\n",
      "Epoch 140/200, VAE Loss = 4117.24\n",
      "Epoch 150/200, VAE Loss = 3954.61\n",
      "Epoch 160/200, VAE Loss = 3739.48\n",
      "Epoch 170/200, VAE Loss = 3696.18\n",
      "Epoch 180/200, VAE Loss = 3597.91\n",
      "Epoch 190/200, VAE Loss = 3582.14\n",
      "Epoch 200/200, VAE Loss = 3358.71\n",
      "Đã sinh thêm: 1120 mẫu minority bằng VAE\n",
      "Sau khi oversampling bằng VAE:\n",
      "Phân phối lớp trong tập train: {0.0: 1200, 1.0: 1200}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:41:39.875409Z",
     "start_time": "2025-01-11T23:41:31.299983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#-------------\n",
    "# Bước E: TRAIN MODEL TRANSFORMER DETECTOR NHƯ THƯỜNG LỆ\n",
    "#-------------\n",
    "model = TransformerDetector(input_size=input_dim).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 20\n"
   ],
   "id": "a661efc75c6d506c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.2071\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.94      1.00      0.97       300\n",
      "     Class 1       1.00      0.05      0.10        20\n",
      "\n",
      "    accuracy                           0.94       320\n",
      "   macro avg       0.97      0.53      0.53       320\n",
      "weighted avg       0.94      0.94      0.91       320\n",
      "\n",
      "AUC-ROC: 0.6415\n",
      "Epoch 2/20, Loss: 0.1278\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.94      1.00      0.97       300\n",
      "     Class 1       1.00      0.05      0.10        20\n",
      "\n",
      "    accuracy                           0.94       320\n",
      "   macro avg       0.97      0.53      0.53       320\n",
      "weighted avg       0.94      0.94      0.91       320\n",
      "\n",
      "AUC-ROC: 0.7367\n",
      "Epoch 3/20, Loss: 0.1187\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.94      1.00      0.97       300\n",
      "     Class 1       1.00      0.05      0.10        20\n",
      "\n",
      "    accuracy                           0.94       320\n",
      "   macro avg       0.97      0.53      0.53       320\n",
      "weighted avg       0.94      0.94      0.91       320\n",
      "\n",
      "AUC-ROC: 0.7570\n",
      "Epoch 4/20, Loss: 0.1085\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.94      1.00      0.97       300\n",
      "     Class 1       1.00      0.05      0.10        20\n",
      "\n",
      "    accuracy                           0.94       320\n",
      "   macro avg       0.97      0.53      0.53       320\n",
      "weighted avg       0.94      0.94      0.91       320\n",
      "\n",
      "AUC-ROC: 0.8497\n",
      "Epoch 5/20, Loss: 0.0997\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.99      0.97       300\n",
      "     Class 1       0.75      0.30      0.43        20\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.85      0.65      0.70       320\n",
      "weighted avg       0.94      0.95      0.94       320\n",
      "\n",
      "AUC-ROC: 0.8682\n",
      "Epoch 6/20, Loss: 0.0838\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.99      0.97       300\n",
      "     Class 1       0.67      0.40      0.50        20\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.81      0.69      0.74       320\n",
      "weighted avg       0.94      0.95      0.94       320\n",
      "\n",
      "AUC-ROC: 0.9222\n",
      "Epoch 7/20, Loss: 0.0907\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.95      1.00      0.97       300\n",
      "     Class 1       1.00      0.15      0.26        20\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.97      0.57      0.62       320\n",
      "weighted avg       0.95      0.95      0.93       320\n",
      "\n",
      "AUC-ROC: 0.9387\n",
      "Epoch 8/20, Loss: 0.0805\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.96      0.96       300\n",
      "     Class 1       0.45      0.50      0.48        20\n",
      "\n",
      "    accuracy                           0.93       320\n",
      "   macro avg       0.71      0.73      0.72       320\n",
      "weighted avg       0.93      0.93      0.93       320\n",
      "\n",
      "AUC-ROC: 0.9263\n",
      "Epoch 9/20, Loss: 0.0753\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.95      0.96       300\n",
      "     Class 1       0.43      0.60      0.50        20\n",
      "\n",
      "    accuracy                           0.93       320\n",
      "   macro avg       0.70      0.77      0.73       320\n",
      "weighted avg       0.94      0.93      0.93       320\n",
      "\n",
      "AUC-ROC: 0.9142\n",
      "Epoch 10/20, Loss: 0.0933\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      1.00      0.98       300\n",
      "     Class 1       1.00      0.30      0.46        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.98      0.65      0.72       320\n",
      "weighted avg       0.96      0.96      0.94       320\n",
      "\n",
      "AUC-ROC: 0.9285\n",
      "Epoch 11/20, Loss: 0.0717\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.95      0.99      0.97       300\n",
      "     Class 1       0.60      0.30      0.40        20\n",
      "\n",
      "    accuracy                           0.94       320\n",
      "   macro avg       0.78      0.64      0.69       320\n",
      "weighted avg       0.93      0.94      0.93       320\n",
      "\n",
      "AUC-ROC: 0.8563\n",
      "Epoch 12/20, Loss: 0.0960\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.98      0.98       300\n",
      "     Class 1       0.67      0.50      0.57        20\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.82      0.74      0.77       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "AUC-ROC: 0.9332\n",
      "Epoch 13/20, Loss: 0.0913\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.99      0.98       300\n",
      "     Class 1       0.73      0.40      0.52        20\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.84      0.70      0.75       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "AUC-ROC: 0.9388\n",
      "Epoch 14/20, Loss: 0.0569\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.98       300\n",
      "     Class 1       0.81      0.65      0.72        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.89      0.82      0.85       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9440\n",
      "Epoch 15/20, Loss: 0.0588\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.99      0.98       300\n",
      "     Class 1       0.85      0.55      0.67        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.91      0.77      0.82       320\n",
      "weighted avg       0.96      0.97      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9687\n",
      "Epoch 16/20, Loss: 0.0465\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.99      0.98       300\n",
      "     Class 1       0.82      0.45      0.58        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.89      0.72      0.78       320\n",
      "weighted avg       0.96      0.96      0.95       320\n",
      "\n",
      "AUC-ROC: 0.9537\n",
      "Epoch 17/20, Loss: 0.0543\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.99      0.98       300\n",
      "     Class 1       0.75      0.45      0.56        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.86      0.72      0.77       320\n",
      "weighted avg       0.95      0.96      0.95       320\n",
      "\n",
      "AUC-ROC: 0.9137\n",
      "Epoch 18/20, Loss: 0.0538\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.99       300\n",
      "     Class 1       0.82      0.70      0.76        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.90      0.84      0.87       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9610\n",
      "Epoch 19/20, Loss: 0.0438\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.99      0.98       300\n",
      "     Class 1       0.86      0.60      0.71        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.92      0.80      0.84       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9750\n",
      "Epoch 20/20, Loss: 0.0510\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.98       300\n",
      "     Class 1       0.76      0.65      0.70        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.87      0.82      0.84       320\n",
      "weighted avg       0.96      0.97      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9752\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:44:20.816058Z",
     "start_time": "2025-01-11T23:44:12.144132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_detector(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    print(\"Classification Report on Test Set:\")\n",
    "    evaluate_with_classification_report_and_auc(model, test_loader, device)"
   ],
   "id": "690c5f98f706b870",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0370\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      1.00      0.99       300\n",
      "     Class 1       0.92      0.60      0.73        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.95      0.80      0.86       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9707\n",
      "Epoch 2/20, Loss: 0.0499\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.99       300\n",
      "     Class 1       0.87      0.65      0.74        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.92      0.82      0.86       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9753\n",
      "Epoch 3/20, Loss: 0.0343\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.99      0.98       300\n",
      "     Class 1       0.86      0.60      0.71        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.92      0.80      0.84       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9637\n",
      "Epoch 4/20, Loss: 0.0272\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      1.00      0.98       300\n",
      "     Class 1       0.90      0.45      0.60        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.93      0.72      0.79       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9707\n",
      "Epoch 5/20, Loss: 0.0433\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      1.00      0.98       300\n",
      "     Class 1       0.90      0.45      0.60        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.93      0.72      0.79       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9670\n",
      "Epoch 6/20, Loss: 0.0316\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.98      0.98       300\n",
      "     Class 1       0.76      0.80      0.78        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.87      0.89      0.88       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9748\n",
      "Epoch 7/20, Loss: 0.0420\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.98       300\n",
      "     Class 1       0.76      0.65      0.70        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.87      0.82      0.84       320\n",
      "weighted avg       0.96      0.97      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9498\n",
      "Epoch 8/20, Loss: 0.0235\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.98      0.98       300\n",
      "     Class 1       0.67      0.60      0.63        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.82      0.79      0.80       320\n",
      "weighted avg       0.95      0.96      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9738\n",
      "Epoch 9/20, Loss: 0.0199\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.99       300\n",
      "     Class 1       0.88      0.70      0.78        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.93      0.85      0.88       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9780\n",
      "Epoch 10/20, Loss: 0.0255\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.99       300\n",
      "     Class 1       0.79      0.75      0.77        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.89      0.87      0.88       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9740\n",
      "Epoch 11/20, Loss: 0.0214\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.99       300\n",
      "     Class 1       0.87      0.65      0.74        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.92      0.82      0.86       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9390\n",
      "Epoch 12/20, Loss: 0.0351\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      1.00      0.98       300\n",
      "     Class 1       1.00      0.50      0.67        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.98      0.75      0.83       320\n",
      "weighted avg       0.97      0.97      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9737\n",
      "Epoch 13/20, Loss: 0.0264\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.99      0.98       300\n",
      "     Class 1       0.73      0.55      0.63        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.85      0.77      0.80       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9293\n",
      "Epoch 14/20, Loss: 0.0314\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.98      0.98       300\n",
      "     Class 1       0.71      0.60      0.65        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.84      0.79      0.81       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9548\n",
      "Epoch 15/20, Loss: 0.0315\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.98      0.97       300\n",
      "     Class 1       0.64      0.45      0.53        20\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.80      0.72      0.75       320\n",
      "weighted avg       0.94      0.95      0.95       320\n",
      "\n",
      "AUC-ROC: 0.9403\n",
      "Epoch 16/20, Loss: 0.0344\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      1.00      0.99       300\n",
      "     Class 1       0.92      0.60      0.73        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.95      0.80      0.86       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9710\n",
      "Epoch 17/20, Loss: 0.0193\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      1.00      0.98       300\n",
      "     Class 1       1.00      0.35      0.52        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.98      0.68      0.75       320\n",
      "weighted avg       0.96      0.96      0.95       320\n",
      "\n",
      "AUC-ROC: 0.9737\n",
      "Epoch 18/20, Loss: 0.0207\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.99       300\n",
      "     Class 1       0.79      0.75      0.77        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.89      0.87      0.88       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9740\n",
      "Epoch 19/20, Loss: 0.0226\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.98       300\n",
      "     Class 1       0.81      0.65      0.72        20\n",
      "\n",
      "    accuracy                           0.97       320\n",
      "   macro avg       0.89      0.82      0.85       320\n",
      "weighted avg       0.97      0.97      0.97       320\n",
      "\n",
      "AUC-ROC: 0.9500\n",
      "Epoch 20/20, Loss: 0.0204\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.98      0.98       300\n",
      "     Class 1       0.68      0.75      0.71        20\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.83      0.86      0.85       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "\n",
      "AUC-ROC: 0.9653\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f2330c383722c013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b9806a65d5ef0b01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1cf0de771d15201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e0277fb2f9ab552"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e8b301b3dd9e42ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41d31bce7d60b2c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cc3500aa63939190"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2848270f71f85773"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1dad87b69d30bc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa008e412270a54a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd1ed5a40c51b66d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "baa3bab98eb64315"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89c3ed4b1fde275d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc94459af00eccd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a7979a1898f41ba9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1a3fd109257c067d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "76f8cd5cfa3ecd91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a8aacebc018b965"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cfc5a60dc15e6be5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf5f73574e296ea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aac568ec1efdcd1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e550d7ef6e99a299"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14610b707092d761"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "773fe629025089ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a12f0b7c72cc6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "73ded0c387c3f22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5eefd136cc08e864"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef5a62d46957f86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56c091b40b382669"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c638a420272e2e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "273e6bccc3607ad6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b9414b1f4d3e6e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf80b540920b9c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56af1c80491063d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c5f897dec74a49f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "937ae6ab3f37ca1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d28e1546bb6747a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d24d00bb5cb742ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14c8637e53e0950c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d00f3664525666b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f735635761b1c415"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "16990e5c1a426dc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e2a45488770c5ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4bef7cc80b8d3a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b34ae88ebbdf3fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a8a9e439d41a0929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "64ba8cccaa1037fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6974e7abddf3e0d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27e1f8353265d893"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f875ad80d15e543e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "88f280fb7a45345d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "17da04539b7161c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37ff79b64218153d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "48b58be985520860"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd96b4d8748c9f7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8e7a35d286a17926"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "537a9ffe932da337"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56630d6ce718f55e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45886e2376dec6c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
